# 人工智能导论实验

~~这是实验报告, 不是论文. 因此我以一种平时交流的语气而并非过于刻板的书面语写下的实验报告. 希望助教检查愉快~~

## 实验一 黑白棋AI算法

这个实验有一部分是和同学交流写的, 我和几位同学一起debug了. 但是代码虽然是大家商讨得出的结论, 但是还真的都是自己写的.

### 1. 代码

代码文件一共四个, **main.cpp**, **DRAW.h**, **MTCS.h**, **MYTIME.h**, 其中**main.cpp**是主程序, **DRAW.h**用于实现下棋的规则, **MTCS.h**用于决策, **MYTIME.h**用于计算时间

代码如下. 

```c++
//main.cpp
#include<stdio.h>
#include<stdlib.h>
#include<time.h>
#include<sys/time.h>
#include<windows.h>
#include"MTCS.h"
#include"DRAW.h"
#include"MYTIME.h" 
//决定先后手，机0人1 
#define FIRST 0
#define NEXT 0
main(){
	timeval tb,ta,t;
	int err;
	MapInit();
	PrintMap();
	srand(time(NULL));
	while(1){
		if(AbleDraw(map,BLACK)){
			printf("先手执O下棋\n");
			gettimeofday(&tb,0);
#if FIRST==0
			Intelligence(WHITE);
#else
			Human(WHITE);
#endif
			gettimeofday(&ta,0);
			t=TimeDistance(tb,ta);
			printf("用时%lfms\n",(double)(t.tv_sec*1000+t.tv_usec/1000.0));
			if(t.tv_sec>=60){
				printf("超时失败\n");
				exit(1);
			}
			PrintMap();
		}
		if(AbleDraw(map,WHITE)){
			printf("后手执X下棋\n");
			gettimeofday(&tb,0);
#if NEXT==0
			Intelligence(BLACK);
#else
			Human(BLACK);
#endif
			gettimeofday(&ta,0);
			t=TimeDistance(tb,ta);
			printf("用时%lfms\n",(double)(t.tv_sec*1000+t.tv_usec/1000.0));
			if(t.tv_sec>=60){
				printf("超时失败\n");
				exit(1);
			}
			PrintMap();
		}
		if(End()==1){
			printf("游戏结束\n");
			err=FindWin(map);
			if(err>0){
				printf("先手胜%d子\n",err);
			}
			else if(err<0){
				printf("后手胜%d子\n",err);
			}
			else{
				printf("平局\n");
			}
			break;
		}
	}
}
```

```c++
//DRAW.h
#ifndef __DRAW_H
#define __DRAW_H
//这是用于下翻转棋的操作，部分代码借鉴于同学，使用时请手动修改LINE定义 
//由于赶工繁忙，可能有些许bug，对此本人深感抱歉。如有建设性建议，可通过QQ：1345578933联系（麻治昊，20210612于中国科学技术大学） 
#include<stdio.h>
//棋盘行列，必须是偶数 
#define LINE 8
//白方先行 
#define WHITE 1
#define BLACK -1
//棋盘 
int map[LINE][LINE]={0};
int Rev(int x){
	//反转棋子 
	return(-x);
}
void MapInit() {
	//棋盘初始化 
	map[LINE/2-1][LINE/2-1]=BLACK;
	map[LINE/2-1][LINE/2]=WHITE;
	map[LINE/2][LINE/2-1]=WHITE;
	map[LINE/2][LINE/2]=BLACK;
}
void PrintMap(){
	//打印棋盘 
	int flag1,flag2;
	for(flag1=0;flag1<LINE;flag1++){
		for(flag2=0;flag2<LINE;flag2++){
			if(map[flag1][flag2]==NULL){
				printf("   |");
			}
			else if(map[flag1][flag2]==WHITE){
				printf(" O |");
			}
			else if(map[flag1][flag2]==BLACK){
				printf(" X |");
			}
		}
		printf("\n\n");
	}
}
bool ValidStep(int map[LINE][LINE],int x,int y,int col){
	//判断下的位置是否合法 
	int i,j,op;
	op=Rev(col);
	if(map[x][y]!=NULL||x>=LINE||x<0||y>=LINE||y<0){
		return false;
	}
	j=y+1;
	while(j<LINE-1&&map[x][j]==op){
		j++;
		if(map[x][j]==col){
			return true;
		}
	}
	j=y-1;
	while(j>0&&map[x][j]==op){
		j--;
		if(map[x][j]==col){
			return true;
		}
	}
	i=x+1;
	while(i<LINE-1&&map[i][y]==op){
		i++;
		if(map[i][y]==col){
			return true;
		}
	}
	i=x-1;
	while(i>0&&map[i][y]==op){
		i--;
		if(map[i][y]==col){
			return true;
		}
	}
	i=x+1;
	j=y-1;
	while(i<LINE-1&&j>0&&map[i][j]==op){
		i++;
		j--;
		if(map[i][j]==col){
			return true;
		}
	}
	i=x+1;
	j=y+1;
	while(i<LINE-1&&j<LINE-1&&map[i][j]==op){
		i++;
		j++;
		if(map[i][j]==col){
			return true;
		}
	}
	i=x-1;
	j=y+1;
	while(i>0&&j<LINE-1&&map[i][j]==op){
		i--;
		j++;
		if(map[i][j]==col){
			return true;
		}
	}
	i=x-1;
	j=y-1;
	while(i>0&&j>0&&map[i][j]==op){
		i--;
		j--;
		if(map[i][j]==col){
			return true;
		}
	}
	return false;
}
bool DrawIn(int map[LINE][LINE],int x,int y,int col){
	//判断所下位置是否合法并开启反转 
	int op,flag,i,j,a,b;
	if(map[x][y]!=NULL||x>=LINE||x<0||y>=LINE||y<0){
		return false;
	}
	op=Rev(col);
	flag=false;
	j=y+1;
	while(j<LINE-1&&map[x][j]==op){
		j++;
		if (map[x][j]==col){
			for(b=y+1;b<j;b++)
				map[x][b]=col;
			flag=true;
			break;
		}
	}
	j=y-1;
	while(j>0&&map[x][j]==op){
		j--;
		if(map[x][j]==col){
			for(b=y-1;b>j;b--){
				map[x][b] = col;
			}
			flag=true;
			break;
		}
	}
	i=x+1;
	while(i<LINE-1&&map[i][y]==op){
		i++;
		if (map[i][y]==col){
			for(a=x+1;a<i;a++){
				map[a][y]=col;
			}
			flag=true;
			break;
		}
	}
	i=x-1;
	while(i>0&&map[i][y]==op){
		i--;
		if(map[i][y]==col){
			for(a=x-1;a>i;a--)
				map[a][y]=col;
			flag=true;
			break;
		}
	}
	i=x+1;
	j=y-1;
	while(i<LINE-1&&j>0&&map[i][j]==op){
		i++;
		j--;
		if(map[i][j]==col){
			for(a=x+1,b=y-1;a<i&&b>j;a++,b--)
				map[a][b]=col;
			flag=true;
			break;
		}
	}
	i=x+1;
	j=y+1;
	while(i<LINE-1&&j<LINE-1&&map[i][j]==op){
		i++;
		j++;
		if(map[i][j]==col){
			for(a=x+1,b=y+1;a<i&&b<j;a++,b++){
				map[a][b] = col;
			}
			flag=true;
			break;
		}
	}
	i=x-1;
	j=y+1;
	while(i>0&&j<LINE-1&&map[i][j]==op){
		i--;
		j++;
		if(map[i][j]==col){
			for(a=x-1,b=y+1;a>i&&b<j;a--,b++){
				map[a][b] = col;
			}
			flag=true;
			break;
		}
	}
	i=x-1;
	j=y-1;
	while(i>0&&j>0&&map[i][j]==op){
		i--;
		j--;
		if(map[i][j]==col){
			for(a=x-1,b=y-1;a>i&&b>j;a--,b--){
				map[a][b]=col;
			} 
			flag=true;
			break;
		}
	}
	if(!flag){
		return false;
	}
	map[x][y]=col;
	return true;
}
bool AbleDraw(int map[LINE][LINE],int col){
	//判断可否进行下棋 
	int i,j; 
	for(i=0;i<LINE;i++){
		for(j=0;j<LINE;j++){
			if(ValidStep(map,i,j,col)){
				return true;
			}
		}
	}
	return false;
}
void Human(int colour){
	int x,y;
	printf("请下棋，输入格式：<x y>，先输入行号后输入列号\n");
	scanf("%d %d",&x,&y);
	while(DrawIn(map,x-1,y-1,colour)==0){
		printf("非法输入\n");
		scanf("%d %d",&x,&y);
	}
}
bool End(){
	//判断游戏结束 
	if(!AbleDraw(map,BLACK)||!AbleDraw(map,WHITE)){
		return true;
	}
	return false;
}
int FindWin(int map[LINE][LINE]){
	//找获胜方 
	int i,j,x,y;
	i=0;
	j=0;
	x=0;
	y=0;
	for(;x<LINE;x++){
		for(y=0;y<LINE;y++) {
			if(map[x][y]==WHITE){
				i++;
			}
			if(map[x][y]==BLACK){
				j++;
			}
		}
	}
	return(i-j);
}
#endif
```

```c++
//MTCS.h
#ifndef __MTCS_H
#define __MTCS_H
//这是用于Monte Carlo树的操作，部分代码借鉴于同学，使用时请手动修改UCT，MAXCHILD，MAXPOINT定义 
//由于赶工繁忙，可能有些许bug，对此本人深感抱歉。如有建设性建议，可通过QQ：1345578933联系（麻治昊，20210612于中国科学技术大学） 
#include<stdlib.h>
#include<math.h>
#include<windows.h>
#include"DRAW.h"
//UCT超参
#define UCT 0.5
//最多子节点
#define MAXCHILD 50 
//最多尝试节点数
#define MAXPOINT 5000
struct Node{
	//总模拟受益,白棋胜数
	int q=0;
	//总访问次数
	int n=0;
	//棋盘状态
	int status[LINE][LINE];
	//哪一方的回合，甚至可能憋死 
	int turn;
	//父子节点 
	Node *parent=NULL;
	Node *child[MAXCHILD]={NULL};
	//子节点数
	int chnum=0;
};
double CalcUct(Node *p){
	//计算UCT权重 
	int col;
	double t;
	col=p->parent->turn;
	if(col==WHITE){
		t=(p->q/p->n)+UCT*sqrt(log(p->parent->n)/p->n);
	}
	if(col==BLACK){
		t=(1-(p->q/p->n))+UCT*sqrt(log(p->parent->n)/p->n);
	}
	return t;
}
bool Genchild(Node *p){
	//获取子节点 
	int x,y,chnum,i,j,col;
	chnum=0;
	Node *q;
	col=p->turn;
	if(col==NULL){
		return false;
	}
	for(x=0;x<LINE;x++){
		for(y=0;y<LINE;y++){
			if(ValidStep(p->status,x,y,col)){
				if(!(q=new Node)){
					exit(1);
				}
				for(i=0;i<LINE;i++){
					for(j=0;j<LINE;j++) {
						q->status[i][j]=p->status[i][j];
					}
				}
				q->parent=p;
				DrawIn(q->status,x,y,col);
				if(AbleDraw(q->status,Rev(col))){
					q->turn=Rev(col);
				}
				else if(AbleDraw(q->status,col)){
					q->turn=col;
				}
				else{
					q->turn=NULL;
				}
				p->child[chnum]=q;
				chnum++;
			}
		}
	}
	p->chnum=chnum;
	return true;
}
Node *SelectChild(Node *p,int colour){
	//选择子节点 
	int num,i,maxseq,minseq,seq;
	double max,min,tmp;
	Node **q;
	num=p->chnum;
	for(i=0;i<num;i++){
		if(p->child[i]->n==0){
			return p->child[i];
		}
	}
	if(colour==WHITE){
		minseq=0;
		min=CalcUct(p->child[0]);
		seq=1;
		q=p->child;
		while(seq<num){
			if((tmp=CalcUct(q[seq]))<min){
				min=tmp;
				minseq=seq;
			}
			seq++;
		}
		return q[minseq];
	}
	if(colour==BLACK){
		maxseq=0;
		max=CalcUct(p->child[0]);
		seq=1;
		q=p->child;
		while(seq<num){
			if((tmp=CalcUct(q[seq]))>max){
				max=tmp;
				maxseq=seq;
			}
			seq++;
		}
		return q[maxseq];
	}
}
int Step(int map[LINE][LINE],int &col){
	//单步模拟 
	int stepnum,x,y,stepx[MAXCHILD],stepy[MAXCHILD],step;
	stepnum=0;
	if(col==NULL){
		return 0;
	}
	for(x=0;x<LINE;x++){
		for(y=0;y<LINE;y++){
			if(ValidStep(map,x,y,col)){
					stepx[stepnum]=x;
					stepy[stepnum]=y;
					stepnum++;
			}
		}
	}
	if(stepnum==0){
		return 2;
	}
	step=rand()%stepnum;
	DrawIn(map,stepx[step],stepy[step],col);
	if(AbleDraw(map,Rev(col))){
		col=Rev(col);
		return 1;
	}
	else if(AbleDraw(map,col)){
		return 1;
	}
	else{
		col=NULL;
		return 1;
	}
}
int Roll(Node *p){
	//随机模拟，返回值为白棋方收益 
	int x,y,map[LINE][LINE];
	int col=p->turn;
	for(x=0;x<LINE;x++){
		for(y=0;y<LINE;y++){
			map[x][y]=p->status[x][y];
		}
	}
	if(col==NULL){
		if(FindWin(map)==WHITE)
			return 1;
		else{
			return 0;
		}
	}
	while(col!=NULL){
		if(Step(map,col)==2){
			return 2;
		}
	}
	if(FindWin(map)==WHITE)
		return 1;
	else{
		return 0;
	}
}
bool FeedBack(Node *p,int q){
	//反向传播 
	while(p!=NULL){
		p->q+=q;
		p->n+=1;
		p=p->parent;
	}
	return true;
}
void DeleteTree(Node *root){
	//释放树节点 
	int i;
	if(root==NULL){
		return;
	}
	for(i=0;i<root->chnum;i++){
		DeleteTree(root->child[i]);
	}
	delete root;
}
void Intelligence(int colour){
	//人工智能决策 
	Node *root,*p,**q;
	int x,y,i,j,maxseq,Max,Seq,temp,(*a)[LINE],err;
	if(!(root = new Node)){
		exit(1);
	}
	for(x=0;x<LINE;x++){
		for(y=0;y<LINE;y++){
			root->status[x][y]=map[x][y];
		}
	}
	root->turn=colour;
	p=root;
	for(i=0;i<MAXPOINT;i++){
		p=root;
		while(p->chnum!=0){
			p=SelectChild(p,colour);
		}
		err=Roll(p);
		if(err==2){
			printf("无子可下\n");
			err=FindWin(map);
			if(err>0){
				printf("先手胜%d子\n",err);
			}
			else if(err<0){
				printf("后手胜%d子\n",err);
			}
			else{
				printf("平局\n");
			}
			exit(1);
		}
		FeedBack(p,err);
		Genchild(p);
	}
	maxseq=0;
	Max=(root->child[0]->n);
	Seq=1;
	q=root->child;
	while(Seq<root->chnum){
		if((temp=q[Seq]->n)>Max){
			Max=temp;
			maxseq=Seq;
		}
		Seq++;
	}
	//寻找下一步
	a=root->child[maxseq]->status;
	for(x=0;x<LINE;x++){
		for(y=0;y<LINE;y++){
			if(root->status[x][y]==NULL&&a[x][y]!=NULL){
				i=x;
				j=y;
				break;
			}
		}
	}
	printf("MCTS:(%d,%d)\n",i+1,j+1);
	DrawIn(map,i,j,colour);
}
#endif
```

```C++
//MYTIME.h
#ifndef __MYTIME_H
#define __MYTIME_H
//这是用于求时间差的操作 
//由于赶工繁忙，可能有些许bug，对此本人深感抱歉。如有建设性建议，可通过QQ：1345578933联系（麻治昊，20210510于中国科学技术大学） 
#include<stdio.h>
#include<stdlib.h>
#include<sys/time.h>
//函数内容 
timeval TimeDistance(timeval timeBefore,timeval timeAfter){
	//计算时间差并以原格式返回 
	timeval timeDistance;
	int numBefore,numAfter,numDistance; 
	numBefore=timeBefore.tv_sec*1000000+timeBefore.tv_usec;
	numAfter=timeAfter.tv_sec*1000000+timeAfter.tv_usec;
	numDistance=numAfter-numBefore;
	timeDistance.tv_sec=numDistance/1000000;
	timeDistance.tv_usec=numDistance%1000000;
	return(timeDistance);
}
#endif
```

### 2. 分析

此次难度核心在于如何利用好MTCS搜索, 而下棋规则以及人机运行内容较为简单. 我先写好了二人对战的主框架, 然后引进AI的. 人下棋用的是**DRAW.h**的

```c++
void Human(int colour);
```

函数, 而AI下棋用的是**MTCS.h**的

```c++
void Intelligence(int colour);
```

函数.

决策的流程书上有, 我也在这里重复一遍吧. 相关代码在**MTCS.h**里.

1. 选择. 

   选择指算法从搜索树的根节点开始, 向下递归选择子节点, 直至到达叶子节点或者到达具有还未被扩展过的子节点的节点L. 这个向下递归选择过程可由UCB1算法来实现, 在递归选择过程中记录下每个节点被选择次数和每个节点得到的奖励均值.  这里对应着

   ```c++
   Node *SelectChild(Node *p,int colour);
   ```

   函数. 

2. 扩展. 

   如果节点 L 不是一个终止节点 ( 或对抗搜索的终局节点 ) , 则随机扩展它的一个未被扩展过的后继边缘节点M. 这里对应着

   ```c++
   bool Genchild(Node *p);
   ```

   函数. 

3. 模拟. 

   从节点M出发, 模拟扩展搜索树, 直到找到一个终止节点. 模拟过程使用的策略和采用UCB1算法实现的选择过程并不相同, 前者通常会使用比较简单的策略, 例如使用随机策略. 这里对应着

   ```c++
   int Roll(Node *p);
   ```

   函数. 

4. 反向传播. 

   用模拟所得结果 ( 终止节点的代价或游戏终局分数 ) 回溯更新模拟路径中M以上 ( 含M ) 节点的奖励均值和被访问次数. 这里对应着

   ```c++
   bool FeedBack(Node *p,int q);
   ```

   函数. 

其中, 模拟步骤中的子函数

```c++
int Step(int map\[LINE][LINE],int &col);
```

是利用了随机算法的, 有一定概率会以等概率随机找一个可行解. 而比较函数的比较对象则是

```c++
double CalcUct(Node *p);
```

函数, 该函数就包含了PPT上的公式

### 3. 运行示例

1. 人机对战

   此时, 需要修改**main.cpp**的**FIRST**与**NEXT**宏定义分部为1和0, 代表先手人后手AI, 并重新编译运行.

   有一说一, 人机模式真的很难赢, 利用人机的搜索漏洞, 好不容易赢了一局

   <img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614144436427.png" alt="image-20210614144436427" style="zoom: 50%;" />

   根据实验数据发现, AI横向扩展50, 搜索节点5000时, 平均反应时间为130ms.

2. 机器之间的对决

   此时, 需要修改**main.cpp**的**FIRST**与**NEXT**宏定义分部为0和0, 代表先手和后手都是AI, 并重新编译运行. 在视觉效果上, 这个就比较精彩了, 机器之间的对决中,每一步都是局部最优解, 某终局如下所示.

   <img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614143048028.png" alt="image-20210614143048028" style="zoom:50%;" />

   看了几盘棋, 不难发现几乎都是先手胜利的. 而且先手运算用时平均63ms, 后手平均用时300ms. 因此我认为, 这种棋和五子棋有类似之处, 那就是先手优势很大. 如果不加以禁手, 双方都是最优解的时候, 先手必胜.

   

## 实验三 线性回归模型

这个实验是完全我一个人写的, 甚至百度和CSDN也都没查. 代码的一部分库函数来源于上学期密码学在BMP图像加密的内容, 当然也是我自己写的.

### 1. 代码

代码文件一共四个, **main.cpp**, **PROCESS.h**, **RAND.h**, **BMP.h**, 其中**main.cpp**是主程序, **PROCESS.h**用于处理数组产生或消除信号噪声, **RAND.h**用于生成随机数, **BMP.h**用于读取BMP图像.

代码如下. 

```c++
//main.cpp
#include<stdio.h>
#include<stdlib.h>
#include<math.h>
#include"BMP.h"
#include"PROCESS.h"
//定义噪音
#define NOISER 0.5
#define NOISEG 0.5
#define NOISEB 0.5
//定义噪音文件和重做文件路径
#define NOISEFILE "C:\\Users\\ASUS\\Desktop\\noise.bmp"
#define REMAKEFILE "C:\\Users\\ASUS\\Desktop\\remake.bmp"
//定义二维高斯分部范围
#define RNGX 2 
#define RNGY 2 
main(){
	//调色板字节数，图片像素数，循环标签，像素数组 
	int n,pics,flag;
	//原颜色字节，颜色字节更改，三通道 
	char *array0,*array,*arrayr0,*arrayr,*arrayg0,*arrayg,*arrayb0,*arrayb;
	double err;
	FILE *fin,*fnoise,*fremake;
	//BMP 
	BmpHeader bh;
	BmpInfo bi;
	BmpColor *bc;
	
	//初始化 
	srand(rand()*time(NULL));
	fin=fopen("graph.bmp","rb");
	if(fin==NULL){
		printf("原图读取失败\n");
		return(1);
	}
	fnoise=fopen(NOISEFILE,"wb");
	fremake=fopen(REMAKEFILE,"wb");
	array=NULL;
	bc=NULL;
	n=FileReadBmp(fin,bh,bi,bc);
	FileWriteBmp(fnoise,bh,bi,bc,n);
	FileWriteBmp(fremake,bh,bi,bc,n);
	PrintBmpInfo(bh,bi,bc,n);
	fseek(fin,n+14+40,SEEK_SET);
	fseek(fnoise,0,SEEK_END);
	fseek(fremake,0,SEEK_END);
	pics=bi.picsize;
	array0=(char *)malloc(sizeof(char)*pics);
	array=(char *)malloc(sizeof(char)*pics);
	arrayr0=(char *)malloc(sizeof(char)*bi.width*bi.height);
	arrayr=(char *)malloc(sizeof(char)*bi.width*bi.height);
	arrayg0=(char *)malloc(sizeof(char)*bi.width*bi.height);
	arrayg=(char *)malloc(sizeof(char)*bi.width*bi.height);
	arrayb0=(char *)malloc(sizeof(char)*bi.width*bi.height);
	arrayb=(char *)malloc(sizeof(char)*bi.width*bi.height);
	fread(array0,sizeof(char),pics,fin);
	fseek(fin,n+14+40,SEEK_SET);
	fread(array,sizeof(char),pics,fin);
	
	//操作 
	//生成噪音 
	process(array,pics,NOISER,NOISEG,NOISEB);
	fwrite(array,sizeof(char),pics,fnoise);
	//计算噪音误差 
	err=mistake(array,array0,pics);
	printf("%lf\n",err);
	//图片降噪 
	for(flag=0;flag<pics;flag++){
		if(flag%3==RED){
			arrayr0[flag/3]=array[flag];
			arrayr[flag/3]=array[flag];
		}
		if(flag%3==GREEN){
			arrayg0[flag/3]=array[flag];
			arrayg[flag/3]=array[flag];
		}
		if(flag%3==BLUE){
			arrayb0[flag/3]=array[flag];
			arrayb[flag/3]=array[flag];
		}
	}
	remake(arrayr0,arrayr,arrayg0,arrayg,arrayb0,arrayb,RNGX,RNGY,bi.width,bi.height);
	for(flag=0;flag<pics;flag++){
		if(flag%3==RED){
			array[flag]=arrayr[flag/3];
		}
		if(flag%3==GREEN){
			array[flag]=arrayg[flag/3];
		}
		if(flag%3==BLUE){
			array[flag]=arrayb[flag/3];
		}
	}
	fwrite(array,sizeof(char),pics,fremake);
	//计算重塑误差 
	err=mistake(array,array0,pics);
	printf("%lf\n",err);
	free(array0);
	free(array);
	free(arrayr0);
	free(arrayr);
	free(arrayg0);
	free(arrayg);
	free(arrayb0);
	free(arrayb);
} 
```

```c++
//PROCESS.h
#include<stdio.h>
#include<stdlib.h>
#include<math.h>
#include<string.h>
#include"BMP.h"
#include"RAND.h"
#ifndef __PROCESS_H
#define __PROCESS_H
#define PI 3.1415926535897
//这是用于回归分析处理图像的基本操作。 
//由于赶工繁忙，可能有些许bug，对此本人深感抱歉。如有建设性建议，可通过QQ：1345578933联系（麻治昊，20210610于中国科学技术大学）
int process(char *arr,int arrsize,double pr,double pg,double pb){
	//对24真彩图的颜色进行失真模拟 
	int flag,p;
	for(flag=0;flag<arrsize;flag++){
		if(flag%3==RED){
			p=rand0p(pr);
			if(p==0){
				arr[flag]=0;
			}
		}
		if(flag%3==GREEN){
			p=rand0p(pg);
			if(p==0){
				arr[flag]=0;
			}
		}
		if(flag%3==BLUE){
			p=rand0p(pb);
			if(p==0){
				arr[flag]=0;
			}
		}
	}
	return(0);
}
char repixel(char *in0,int x,int y,int rangex,int rangey,int width,int height){
	//重塑像素点 
	//两个sigma，输出像素值，分母 
	double sigmax,sigmay,out,deno,tmp; 
	int flagx,flagy;
	//初始化 
	tmp=0;
	deno=0;
	out=0;
	sigmax=rangex/3.0;
	sigmay=rangey/3.0;
	//操作 
	if(in0[x*width+y]!=0){
		//不变 
		return(in0[x*width+y]);
	}
	for(flagx=x-rangex;flagx<=x+rangex;flagx++){
		for(flagy=y-rangey;flagy<=y+rangey;flagy++){
			if(flagx>=0&&flagx<height&&flagy>=0&&flagy<width){
				if(in0[flagx*width+flagy]!=0){
					tmp=pow(2*PI*sigmax*sigmay,-1)*exp(-0.5*(pow(flagx-x,2)/pow(sigmax,2)+pow(flagy-y,2)/pow(sigmay,2)));
					deno+=tmp;
					out+=tmp*in0[flagx*width+flagy];
				}
			}
		}
	}
	return((char)(out/deno+0.5));
}
int remake(char *arrayr0,char *arrayr,char *arrayg0,char *arrayg,char *arrayb0,char *arrayb,int rangex,int rangey,int width,int height){
	//对图有效像素点加权平均，左右rangex上下rangey内生成gauss分布，遵从3sigma原则 
	int flag1,flag2;
	for(flag1=0;flag1<height;flag1++){
		for(flag2=0;flag2<width;flag2++){
			arrayr[flag1*width+flag2]=repixel(arrayr0,flag1,flag2,rangex,rangey,width,height);
			arrayg[flag1*width+flag2]=repixel(arrayg0,flag1,flag2,rangex,rangey,width,height);
			arrayb[flag1*width+flag2]=repixel(arrayb0,flag1,flag2,rangex,rangey,width,height);
		}
	}
	return(0);
}
double mistake(char *arr0,char *arr1,int arrsize){
	int flag;
	double err;
	err=0;
	for(flag=0;flag<arrsize;flag++){
		err+=pow(((int)arr0[flag]-(int)arr1[flag]),2)/pow(256,2);
	}
	return err;
} 
#endif
```

```c++
//RAND.h
#include<stdio.h>
#include<stdlib.h>
#include<time.h>
#ifndef __RAND_H
#define __RAND_H
//这是用于回归分析处理图像的基本操作。 
//由于赶工繁忙，可能有些许bug，对此本人深感抱歉。如有建设性建议，可通过QQ：1345578933联系（麻治昊，20210609于中国科学技术大学）
int rand0p(double p){
	//以p概率生成0的01分布，出错返回-1 
	int i;
	if(p>1||p<0){
		return(-1);
	}
	i=rand();
	if((double)i/RAND_MAX<p){
		return(0);
	} 
	else{
		return(1);
	}
}
#endif
```

```c++
//BMP.h
#include<stdio.h>
#include<stdlib.h>
#ifndef __BMP_H
#define __BMP_H
#define BLUE 0
#define GREEN 1
#define RED 2
//这是用于读取BMP图像的基本操作。 
//由于赶工繁忙，可能有些许bug，对此本人深感抱歉。如有建设性建议，可通过QQ：1345578933联系（麻治昊，20201029于中国科学技术大学） 
//BMP文件头 
struct BmpHeader{
	unsigned short type;
	//文件类型，通常BM
	unsigned long size;
	//整个文件大小
	unsigned long reserved;
	//保留位，为0
	unsigned long offbits;
	//图片色块区前的位数，单色位62，16色位118，256色位1078，16位、24位、32位色位54 
};
//BMP信息 
struct BmpInfo{
	unsigned long infosize;
	//该结构体大小，一般为40 
	unsigned long width;	
	//图片横向像素个数 
	unsigned long height;
	//图片竖向像素个数 
	unsigned short plane;
	//图像面数，为1 
	unsigned short pictype;
	//图片类型，单色位1，16色位4，256色位8，16位色位16，24位色位24、32位色位32 
	unsigned long compress;
	//压缩方式，0无压缩，1RLE8，2RLE4，3根据掩码决定
	unsigned long picsize;
	//色块区域字节数，必须是4的倍数 
	unsigned long xppx;
	//横向分辨率，像素/米 
	unsigned long yppx;
	//纵向分辨率，像素/米 
	unsigned long clrused;
	//被用的颜色数目，0表示全部 
	unsigned long clrimp;
	//重要颜色数目，0表示同等重要 
};
//BMP调色板数组单元 
typedef int BmpColor;
//函数内容 
int FileReadBmp(FILE *fp,BmpHeader &bh,BmpInfo &bi,BmpColor *&bc){
	//读取bmp，返回调色板字节数 
	fread(&bh.type,sizeof(short),1,fp);
	fread(&bh.size,sizeof(long),1,fp);
	fread(&bh.reserved,sizeof(long),1,fp);
	fread(&bh.offbits,sizeof(long),1,fp);
	fread(&bi.infosize,sizeof(long),1,fp);
	fread(&bi.width,sizeof(long),1,fp);
	fread(&bi.height,sizeof(long),1,fp);
	fread(&bi.plane,sizeof(short),1,fp);
	fread(&bi.pictype,sizeof(short),1,fp);
	fread(&bi.compress,sizeof(long),1,fp);
	fread(&bi.picsize,sizeof(long),1,fp);
	fread(&bi.xppx,sizeof(long),1,fp);
	fread(&bi.yppx,sizeof(long),1,fp);
	fread(&bi.clrused,sizeof(long),1,fp);
	fread(&bi.clrimp,sizeof(long),1,fp);
	if(bi.pictype==16||bi.pictype==24||bi.pictype==32){
		bc=NULL;
		return(0);
	}
	else if(bi.pictype==1){
		bc=(BmpColor *)calloc(sizeof(BmpColor),2);
		fread(bc,sizeof(BmpColor),2,fp);
		return(8);
	}
	else if(bi.pictype==4){
		bc=(BmpColor *)calloc(sizeof(BmpColor),16);
		fread(bc,sizeof(BmpColor),16,fp);
		return(64);
	}
	else if(bi.pictype==8){
		bc=(BmpColor *)calloc(sizeof(BmpColor),256);
		fread(bc,sizeof(BmpColor),256,fp);
		return(1024);
	}
}
void FileWriteBmp(FILE *fp,BmpHeader bh,BmpInfo bi,BmpColor *bc,int n){
	//写入新的bmp文件头 
	fwrite(&bh.type,sizeof(short),1,fp);
	fwrite(&bh.size,sizeof(long),1,fp);
	fwrite(&bh.reserved,sizeof(long),1,fp);
	fwrite(&bh.offbits,sizeof(long),1,fp);
	fwrite(&bi.infosize,sizeof(long),1,fp);
	fwrite(&bi.width,sizeof(long),1,fp);
	fwrite(&bi.height,sizeof(long),1,fp);
	fwrite(&bi.plane,sizeof(short),1,fp);
	fwrite(&bi.pictype,sizeof(short),1,fp);
	fwrite(&bi.compress,sizeof(long),1,fp);
	fwrite(&bi.picsize,sizeof(long),1,fp);
	fwrite(&bi.xppx,sizeof(long),1,fp);
	fwrite(&bi.yppx,sizeof(long),1,fp);
	fwrite(&bi.clrused,sizeof(long),1,fp);
	fwrite(&bi.clrimp,sizeof(long),1,fp);
	fwrite(bc,sizeof(BmpColor),n/4,fp);
}
void PrintBmpInfo(BmpHeader bh,BmpInfo bi,BmpColor *bc,int n){
	//打印bmp信息头 
	printf("信息如下：\n");
	printf("文件大小：%d Bytes\n",bh.size);
	printf("水平长度：%d pix\n",bi.width);
	printf("垂直长度：%d pix\n",bi.height);
	printf("图片颜色类型：2^%d\n",bi.pictype);
	printf("压缩类型：%d （0无压缩，1RLE8，2RLE4，3根据掩码决定）\n",bi.compress);
	printf("图片色块区大小：%d 个四字节\n",bi.picsize/4);
	printf("水平分辨率：%d ppm （0是未定义）\n",bi.xppx);
	printf("垂直分辨率：%d ppm （0是未定义）\n",bi.yppx);
	printf("使用颜色数：%d （0是全部）\n",bi.clrused);
	printf("重要颜色数：%d （0是全部）\n",bi.clrimp);
	printf("特殊调色板颜色数：%d\n",n/4);
}
#endif
```

### 2. 分析

此实验核心在于**PROCESS.h**的图像数组处理函数. 我选择了BMP24位真彩图像进行处理, 分成RGB三个通道. 

题目要求是生成**(0.8,0.4,0.6)**的噪声, 我为了便于探究, 用宏定义**NOISER**, **NOISEG**, **NOISEB**来输入噪声比例. 生成噪声图片对应的是

```c++
int process(char *arr,int arrsize,double pr,double pg,double pb);
```

函数. 我通过调用**RAND.h**的

```c++
int rand0p(double p);
```

函数生成了p概率为0的Bernouli分布来模拟进行噪声遮罩

另外, 题目还需要恢复噪声. 由于二维图片恢复噪声可以采取周围像素的线性回归, 对应的是

```c++
int remake(char *arrayr0,char *arrayr,char *arrayg0,char *arrayg,char *arrayb0,char *arrayb,int rangex,int rangey,int width,int height);
```

函数. 恢复噪声的时候, 并非每个像素都是有用的, 也就是不能用噪声恢复噪声. 因此对于周围的像素点, 如果通道亮度是0的话, 就不可以当作有效数据进行恢复了.

最后为了比较恢复效果, 还需要一个比较函数, 对应的是

```c++
double mistake(char *arr0,char *arr1,int arrsize);
```

函数, 由于L^2范数较大, 担心溢出, 我在每个像素误差的基础上除以256^2, 也就是最大误差来归一化. 这样处理出来的数据就易于比较了. 

### 3. 运行示例

我采用了一张很著名的计算机图形学的图片, 也就是PlayBoy的某封面女郎. 原图如下.

<img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614150305414.png" alt="image-20210614150305414" style="zoom:50%;" />

经过噪声**(0.8,0.4,0.6)**处理, 其实因为噪声是反过来的, 就相当于进行(0.2,0.6,0.4)产生噪声, 得到下图.

<img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614150523208.png" alt="image-20210614150523208" style="zoom:50%;" />

看起来很有颗粒感的一张图片, 而且很诡异. 之后进行噪声恢复, 得到下图.

<img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614150740371.png" alt="image-20210614150740371" style="zoom:50%;" />

虽然大体上是恢复了, 而且效果比较理想. 但是仍然有一种油画剥离的质感. 接下来看一看前后的比较函数值的对比

<img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614151400853.png" alt="image-20210614151400853" style="zoom:50%;" />

我们发现恢复效果还是比较理想的. 

接下来我们设置噪声为**(0,0,0)**, 也就是没有噪声, 则输出的比较值为

<img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614151521306.png" alt="image-20210614151521306" style="zoom:50%;" />

其中恢复后比较值正常应该为0, 因为无损图片不需要进行恢复. 但是它比较值非0, 这说明有一部分单一通道像素亮度值本身就是0. 而这个输出值相比之下特别小, 也侧面证明了不考虑有效的0像素亮度值而直接忽略, 对图片处理影响较小. 

接下来设置噪声为**(0.1,0.1,0.1)**, 对应的噪声和恢复图片以及输出的比较值如下

![image-20210614152027347](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614152027347.png)

接下来设置噪声为**(0.9,0.9,0.9)**, 对应的噪声和恢复图片以及输出的比较值如下

![image-20210614152132663](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614152132663.png)

我们不难发现, 一定程度内, 噪声越小, 恢复的效果越好. 

## 实验五 深度学习

因为寒假打美赛的时候遇到了一些关于建模方面的内容, 对手写识别有一定的了解基础, 我就从手写识别入手了. 我是用matlab的t-sne算法实现了手写图片识别的功能. 

这个实验因为需要用到很多python相关的知识, 百度和CSDN求助较多, 由于自学, 因此走了好多弯路, 敲了好多没用的代码. 最后没用python做出来, 不得已在网上找了个现成的代码, 我来做代码的分析工作, 也是有很大收获的 ( 其实我通过群里发现很多同学也和我一样的 ). 

### 1. 代码

matlab代码是自己写的

Python代码来源于[CSDN链接](https://blog.csdn.net/qq_43479622/article/details/90906094)

需要先pip install tensorflow等一部分py包, 而且要保证安装的时候, 系统环境变量正常. 我正是因为环境变量错误, 在安装tensorflow的时候卡了好久.

代码文件一共四个, app.py, minist_eval.py, mnist_inference.py, mnist_train.py, 其中app.py是用来读取和识别自己用于测试的图像的, minist_eval.py是用来模拟神经网络测试过程的, mnist_inference.py是用来模拟前向传播并定义了一些训练参数的, mnist_train.py是用来进行实际训练的. 

matlab代码如下. 

```matlab
clc
clear
w='2\2_-1.bmp';%读取文件地址
k=1;
for i=0:9
    for j=1:500
        a=num2str(i);
        b=num2str(j);
        w1=strrep(w,'2',a);
        w2=strrep(w1,'-1',b);
        x=imread(w2);
        y(k,:)=x(:)';
        z(k)=i;
        k=k+1;
    end
end
y1=double(y);
x=tsne(y1);
gscatter(x(:,1),x(:,2),z');
x=tsne(y1,'Algorithm','exact' );
figure;
gscatter(x(:,1),x(:,2),z');

```

Python代码如下. 

```python
# app.py
import os
import glob
import tensorflow as tf
import mnist_inference
import mnist_train
from PIL import Image, ImageFilter
import matplotlib.pyplot as plt
import cv2


def evaluate(pic, pic_name):
    with tf.Graph().as_default() as g:
        x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name='x-input')
        y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name='y-input')
        validate_feed = {x:[pic]}
        y = mnist_inference.inference(x, None)
        result = tf.argmax(y, 1)
        variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)
        variables_to_restore = variable_averages.variables_to_restore()
        saver = tf.train.Saver(variables_to_restore)
        with tf.Session() as sess:
            ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)
            if ckpt and ckpt.model_checkpoint_path:
                saver.restore(sess, ckpt.model_checkpoint_path)
                global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]
                number = sess.run(result, feed_dict=validate_feed)
                pic_name = pic_name.split('\\')[-1]
                print(pic_name,' is :',number[0])
            else:
                print('No checkpoint file found')
                return


def image_prepare(pic_name): 
    # 读取图像，第二个参数是读取方式
    img = cv2.imread(pic_name, 1)
    # 使用全局阈值，降噪
    ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)
    # 把opencv图像转化为PIL图像
    im = Image.fromarray(cv2.cvtColor(th1,cv2.COLOR_BGR2RGB))
    # 灰度化
    im = im.convert('L')
    # 为图片重新指定尺寸
    im = im.resize((28,28), Image.ANTIALIAS)
    # plt.imshow(im)
    # plt.show()
    # 图像转换为list
    im_list = list(im.getdata())
    # 图像灰度反转
    result = [(255-x)*1.0/255.0 for x in im_list]
    return result


def main(argv=None):
    # 把要识别的图片放到下面的文件夹中
    img_path = 'picture/'
    imgs = glob.glob(os.path.join(img_path, '*'))
    for p in imgs:
        # 图像处理：降噪、灰度化、修改尺寸以及灰度反转
        pic = image_prepare(p)
        # 识别图像
        evaluate(pic, p)


if __name__ == '__main__':
    main()

```

```python
# minist_eval.py
import time
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import mnist_inference
import mnist_train
# 每10秒加载一次最新模型，并输出正确率
EVAL_INTERVAL_SECS = 10


def evaluate(mnist):
    with tf.Graph().as_default() as g:
        # 定义输入输出格式
        x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name='x-input')
        y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name='y-input')
        validate_feed = {x: mnist.validation.images, y_: mnist.validation.labels}
        # 计算前向传播的结果
        y = mnist_inference.inference(x, None)
        # 计算正确率
        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
        # 加载模型
        variable_averages = tf.train.ExponentialMovingAverage(mnist_train.MOVING_AVERAGE_DECAY)
        variables_to_restore = variable_averages.variables_to_restore()
        saver = tf.train.Saver(variables_to_restore)
        # 每隔10秒执行一次
        while True:
            with tf.Session() as sess:
                ckpt = tf.train.get_checkpoint_state(mnist_train.MODEL_SAVE_PATH)
                if ckpt and ckpt.model_checkpoint_path:
                    saver.restore(sess, ckpt.model_checkpoint_path)
                    global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]
                    accuracy_score = sess.run(accuracy, feed_dict=validate_feed)
                    print("After %s training step(s), validation accuracy = %g" % (global_step, accuracy_score))
                else:
                    print('No checkpoint file found')
                    return
            time.sleep(EVAL_INTERVAL_SECS)


def main(argv=None):
    mnist = input_data.read_data_sets("../../../datasets/MNIST_data", one_hot=True)
    evaluate(mnist)


if __name__ == '__main__':
    main()

```

```python
# mnist_inference.py
import tensorflow as tf

# 输入层节点数，对于MNIST数据集，这个就等于图片的像素。
INPUT_NODE = 784
# 输出层节点数，对应数字0~9
OUTPUT_NODE = 10
# 隐藏层节点数，这里使用只有一个隐藏层的网络结构
LAYER1_NODE = 500


# 获取变量
def get_weight_variable(shape, regularizer):
    weights = tf.get_variable("weights", shape, initializer=tf.truncated_normal_initializer(stddev=0.1))
    if regularizer != None: tf.add_to_collection('losses', regularizer(weights))
    return weights


# 定义神经网络的前向传播过程
def inference(input_tensor, regularizer):
    with tf.variable_scope('layer1'):

        weights = get_weight_variable([INPUT_NODE, LAYER1_NODE], regularizer)
        biases = tf.get_variable("biases", [LAYER1_NODE], initializer=tf.constant_initializer(0.0))
        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)

    with tf.variable_scope('layer2'):
        weights = get_weight_variable([LAYER1_NODE, OUTPUT_NODE], regularizer)
        biases = tf.get_variable("biases", [OUTPUT_NODE], initializer=tf.constant_initializer(0.0))
        layer2 = tf.matmul(layer1, weights) + biases

    # 返回前向传播的结果
    return layer2

```

```python
# mnist_train.py
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import mnist_inference
import os

# 配置神经网络的参数
BATCH_SIZE = 100
LEARNING_RATE_BASE = 0.8
LEARNING_RATE_DECAY = 0.99
REGULARIZATION_RATE = 0.0001
TRAINING_STEPS = 30000
MOVING_AVERAGE_DECAY = 0.99
# 模型保存的路径和文件名
MODEL_SAVE_PATH = "MNIST_model/"
MODEL_NAME = "mnist_model"


def train(mnist):
    # 定义输入输出placeholder
    x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name='x-input')
    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name='y-input')
    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)
    # 使用mnist_inference.py文件中定义的前向传播的过程。
    y = mnist_inference.inference(x, regularizer)

    global_step = tf.Variable(0, trainable=False)
    # 定义损失函数、学习率、滑动平均操作以及训练过程
    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)
    variables_averages_op = variable_averages.apply(tf.trainable_variables())
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))
    cross_entropy_mean = tf.reduce_mean(cross_entropy)
    loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses'))
    learning_rate = tf.train.exponential_decay(
        LEARNING_RATE_BASE,
        global_step,
        mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY,
        staircase=True)
    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)
    with tf.control_dependencies([train_step, variables_averages_op]):
        train_op = tf.no_op(name='train')
    # 使用tf.train.Saver()类保存模型
    saver = tf.train.Saver()
    with tf.Session() as sess:
        # 初始化所有变量
        tf.global_variables_initializer().run()
        for i in range(TRAINING_STEPS):
            xs, ys = mnist.train.next_batch(BATCH_SIZE)
            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: xs, y_: ys})
            if i % 1000 == 0:
                # 输出当前的训练情况，损失函数的大小
                print("After %d training step(s), loss on training batch is %g." % (step, loss_value))
                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)
        saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)


def main(argv=None):
    mnist = input_data.read_data_sets("../../../datasets/MNIST_data", one_hot=True)
    train(mnist)


if __name__ == '__main__':
    tf.app.run()


```



### 2. 分析

matlab的代码就很好解释了. 

首先读取文件,然后直接利用t-sne算法进行分析即可. 

因为是别人的Python代码, 为了证明自己学到了知识, 我就多讲一讲吧.

1. app.py

   首先, 它包含了一些库进去, os库是调用系统的, glob库是支持程序使用Unix shell风格的通配符匹配符合特定格式的文件和文件夹, tensorflow库就是我们要用来进行深度学习用的库. 接下来是两个自己写的库函数, 也就是**mnist_inference**和**mnist_train**. 另外还有Pillow库( PIL )进行图像处理, 以及matplotlib库实现类似matlab的画函数图像功能. 而cv2就是OpenCV的库

   然后是**evaluate**函数, 是用来读取手写图像并计算出更相似与哪一个数字的, 具体流程为读取图片->与模型拟合->观察输出.

   接下来是**image_prepare**函数, 是用来读取图像并进行二值化操作的 ( 因为黑白图像更便于识别与处理 ) . 

2. minist_eval.py

   首先, 它包含了time库, 是用来计算时间的, 因为后续需要每10s加载一次模型. 当然10s也是可以调整的. 之后就是和上一篇代码类似的添加本地自己写的库函数了. 

   又看到了一个**evaluate**, 这是函数重载, 因为两者传参是不同的. 这个函数的流程是先定义好输入输出格式, 并计算前向传播的结果. 加载模型后比对模型. 每十秒进行一次调整. 

3. mnist_inference.py

   首先, 它还是包含了tensorflow库. 

   之后, 它定义了一些关于训练的参数, 比如输入层节点数, 输出层节点数, 隐藏层节点数等. 输入层节点数是784, 是因为图片有784个像素点, 输出层节点数是10, 分别对应0-9的十个数字. 而隐藏层的节点数是可以自定义的. 

   然后是**get_weight_variable**函数, 用来计算权重以及返回相应节点值. 

   接下来是**inference**函数, 这个函数很重要, 是用来前向传播进行调参的函数. 具体传播过程和PPT上是一样的. 

4. mnist_train.py

   首先仍然是加载了一些库

   然后这个包定义了训练的网络参数, 比如批尺寸, 学习率基数和学习衰减率,  正则化参数, 训练步数, 移动平均衰减等, 还定义了模型的存储路径

   接下来就是最重要的训练函数**train**, 它先设定了一个占位符以便于操作后续内容用于输入输出, 然后进行核心的训练过程. 训练结束后, 保存并输出结果, 结束训练. 

### 3. 运行示例

代码要求图片必须是728像素的, 也就是标准的28*28的正方形. 

训练数据如图所示, 以下面的0举例. 

<img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614163957965.png" alt="image-20210614163957965" style="zoom:50%;" />

另外还有相应的1-9的图片. 由于实验样本较多, matlab运行了10min才得出结果图像, 如图所示. 

<img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20210614170526882.png" alt="image-20210614170526882" style="zoom: 33%;" />

这次试验不算圆满地结束了, 但是matlab还是很好用的, 至少实现了图片分类识别的功能.